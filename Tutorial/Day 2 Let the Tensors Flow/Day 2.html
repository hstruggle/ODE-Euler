
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Day 2: Let the Tensors Flow! &#8212; PSST: Parallelised Scalable Simulations in TensorFlow</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../../_static/PSST-favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Day 3: Cells in Silicon" href="../Day%203%20Cells%20in%20Silicon/Day%203.html" />
    <link rel="prev" title="Day 1: Of Numerical Integration and Python" href="../Day%201%20Of%20Numerical%20Integration%20and%20Python/Day%201.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/PSST.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">PSST: Parallelised Scalable Simulations in TensorFlow</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   PSST … It’s well Documented!
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Day 0 : Introduction to the Tutorials
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Day%201%20Of%20Numerical%20Integration%20and%20Python/Day%201.html">
   Day 1: Of Numerical Integration and Python
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Day 2: Let the Tensors Flow!
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Day%203%20Cells%20in%20Silicon/Day%203.html">
   Day 3: Cells in Silicon
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Day%204%20Neurons%20and%20Networks/Day%204.html">
   Day 4: Neurons and Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Day%205%20Optimal%20Mind%20Control/Day%205.html">
   Day 5: Optimal Mind Control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Example%20Implementation%20Locust%20AL/Example.html">
   Example Implementation: Into the Mind of a Locust
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Optional%20Material/Distributed%20TensorFlow/Distributed%20TensorFlow.html">
   Distributed Computing with TensorFlow
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/Tutorial/Day 2 Let the Tensors Flow/Day 2.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/neurorishika/PSST"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/neurorishika/PSST/issues/new?title=Issue%20on%20page%20%2FTutorial/Day 2 Let the Tensors Flow/Day 2.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#an-introduction-to-tensorflow">
   An Introduction to TensorFlow
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-gpu-tpu-vs-cpu">
     Why GPU/TPU vs CPU?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-tensorflow-works">
     How TensorFlow works?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implementing-a-computational-graph-in-tensorflow">
     Implementing a computational graph in TensorFlow
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#efficient-recursion-with-tensorflow">
     Efficient recursion with TensorFlow
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#euler-integration-function-in-tensorflow">
     Euler Integration Function in TensorFlow
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-the-tensorflow-euler-integrator">
     Running the TensorFlow Euler Integrator
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rk4-integration-function-in-tensorflow">
     RK4 Integration Function in TensorFlow
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/neurorishika/PSST/blob/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/Day%202.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/Day%202.ipynb" target="_parent"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p>
<div class="section" id="day-2-let-the-tensors-flow">
<h1>Day 2: Let the Tensors Flow!<a class="headerlink" href="#day-2-let-the-tensors-flow" title="Permalink to this headline">¶</a></h1>
<p>Welcome to Day 2! Today, we start with our discussion with an introduction to TensorFlow followed by implementation of Numerical Integration techniques in TensorFlow.</p>
<div class="section" id="an-introduction-to-tensorflow">
<h2>An Introduction to TensorFlow<a class="headerlink" href="#an-introduction-to-tensorflow" title="Permalink to this headline">¶</a></h2>
<p>TensorFlow is an open-source library that was developed by researchers and engineers in the Google Brain team. TensorFlow has a number of functions that make it particularly suitable for machine learning applications. However, it is primarily an interface for numerical computation.</p>
<div class="section" id="why-gpu-tpu-vs-cpu">
<h3>Why GPU/TPU vs CPU?<a class="headerlink" href="#why-gpu-tpu-vs-cpu" title="Permalink to this headline">¶</a></h3>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/GPUvsCPU.svg"><img alt="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/GPUvsCPU.svg" src="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/GPUvsCPU.svg" width="600" /></a>
<p>The answer lies in the architecture:<br />
<strong>CPU = Faster per Core Processing, Slow but Large Memory Buffer, Few Cores</strong><br />
<strong>GPU/TPU = Slower Processing, Faster but Smaller Memory Buffer, Many Cores</strong></p>
<p>Thus GPUs and TPUs are optimized for large number of simple calculations done parallely. The extent of this  parallelization makes it suitable for vector/tensor manipulation.</p>
</div>
<div class="section" id="how-tensorflow-works">
<h3>How TensorFlow works?<a class="headerlink" href="#how-tensorflow-works" title="Permalink to this headline">¶</a></h3>
<p>All computations in TensorFlow are specified as directed graphs (nodes connected by arrows) known as data flow graphs. Nodes are operations such as addition, multiplication etc. The incoming edges for each node are tensors (scalars, vectors, matrices and higher dimensional arrays), the actual values that are operated upon. The output is also a tensor that results from the computation. For example, consider the following computation where two vectors <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> serve as inputs to the node, a matrix multiplication operation, that produces a matrix <span class="math notranslate nohighlight">\(c\)</span> as output.</p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/matmul.svg"><img alt="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/matmul.svg" src="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/matmul.svg" width="300" /></a>
<p>Here, “matmul” is a node which represents the matrix multiplication operation. a and b are input matrices (2-D tensors) and c is the resultant matrix.</p>
</div>
<div class="section" id="implementing-a-computational-graph-in-tensorflow">
<h3>Implementing a computational graph in TensorFlow<a class="headerlink" href="#implementing-a-computational-graph-in-tensorflow" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First, import Numpy and Matplotlib</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Import TensorFlow</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span> <span class="c1"># for Tensorflow v1.x</span>

<span class="c1"># If using TensorFlow 2.x on CPU only or single GPU setup</span>
<span class="c1"># we suggest using TensorFlow Compat v1 instead as follows:</span>

<span class="kn">import</span> <span class="nn">tensorflow.compat.v1</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">disable_v2_behavior</span><span class="p">()</span>

<span class="c1"># We suggest using TensorFlow v1.x compatibility for better multithreading </span>
<span class="c1"># optimization and disabled eager execution in the earlier version </span>

<span class="c1"># Defining Input Matrices</span>
<span class="n">a_</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">1.</span><span class="p">],[</span><span class="mf">2.</span><span class="p">],[</span><span class="mf">3.</span><span class="p">]]</span> <span class="c1"># a 3x1 column matrix </span>
<span class="n">b_</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">]]</span> <span class="c1"># a 1x3 row matrix </span>

<span class="c1"># Creating nodes in the computation graph </span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">a_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="c1"># 3x1 tensor</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">b_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="c1"># 1x3 tensor</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> 

<span class="c1"># If running TensorFlow 2.x without compat.v1, </span>
<span class="c1"># c will hold the result of the computation.</span>

<span class="c1"># In TensorFlow v1.x, To run the graph, we need to create a session.</span>
<span class="c1"># Creating the session initializes the computational device.</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="c1"># start a session</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="c1"># compute the value of c</span>
<span class="n">sess</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> <span class="c1"># end the session</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[1. 2. 3.]
 [2. 4. 6.]
 [3. 6. 9.]]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="efficient-recursion-with-tensorflow">
<h3>Efficient recursion with TensorFlow<a class="headerlink" href="#efficient-recursion-with-tensorflow" title="Permalink to this headline">¶</a></h3>
<p>To iterate over a list in Python, we used a “for” loop. However, when we implement the same in TensorFlow, putting operations inside a loop replicates the defined computation and chains them together. This results in a long repetitive computation graph with the same operations chained one after the other, resulting in large memory usage and slow computation. TensorFlow provides an alternative with the tf.scan() method.</p>
<p>Say, one wants to recursively apply a function on an initial value but the function takes in additional input at every recursive call, for example, to find the cumulative sum over a list. Every step adds a new element from the list to the last addition. The TensorFlow function tf.scan allows us to easily implement such an iterator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the recursive function that takes in two values the</span>
<span class="c1"># accumulated value and the additional input from a list.</span>
<span class="k">def</span> <span class="nf">recursive_addition</span><span class="p">(</span><span class="n">accumulator</span><span class="p">,</span><span class="n">new_element</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">accumulator</span><span class="o">+</span><span class="n">new_element</span>

<span class="c1"># define the list over which we iterate</span>
<span class="n">elems</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>

<span class="c1"># tf.scan takes in three inputs: the recursive function, the </span>
<span class="c1"># list to iterate over and the initial value. If an initial </span>
<span class="c1"># value is not provided, its taken as the first element of elems.</span>

<span class="c1"># accumulate with no initializer</span>
<span class="n">cum_sum_a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">recursive_addition</span><span class="p">,</span> <span class="n">elems</span><span class="p">)</span> 
<span class="c1"># accumulate with initializer as the number 5</span>
<span class="n">cum_sum_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">recursive_addition</span><span class="p">,</span> <span class="n">elems</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>

<span class="c1"># To automatically close the session after computation in TensorFlow 1.13, Use:</span>
<span class="c1"># with tf.Session() as sess:</span>
<span class="c1">#    output = sess.run(c) </span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">output_a</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cum_sum_a</span><span class="p">)</span>
    <span class="n">output_b</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cum_sum_b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output_a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output_b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 1  3  6 10 15 21]
[ 6  8 11 15 20 26]
</pre></div>
</div>
</div>
</div>
<p>As an <strong>Exercise</strong> use tf.scan to compute the fibonacci sequence.</p>
</div>
<div class="section" id="euler-integration-function-in-tensorflow">
<h3>Euler Integration Function in TensorFlow<a class="headerlink" href="#euler-integration-function-in-tensorflow" title="Permalink to this headline">¶</a></h3>
<p>We now implement Euler’s method using tf.scan to iterate over the time array. Note that the function scan_func that defines each step of Euler’s method, is now an input to tf.scan.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tf_check_type</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y0</span><span class="p">):</span> <span class="c1"># Ensure Input is Correct</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">y0</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span> <span class="ow">and</span> <span class="n">t</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">):</span> 
        <span class="c1"># The datatype of any tensor t is accessed by t.dtype</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Error in Datatype&#39;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">_Tf_Integrator</span><span class="p">():</span>
    
    <span class="k">def</span> <span class="nf">integrate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span> 
        
        <span class="n">time_delta_grid</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">t</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  
        
        <span class="k">def</span> <span class="nf">scan_func</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t_dt</span><span class="p">):</span> 
            <span class="n">t</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="n">t_dt</span>
            <span class="n">dy</span> <span class="o">=</span> <span class="n">dt</span><span class="o">*</span><span class="n">func</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y</span> <span class="o">+</span> <span class="n">dy</span>
        
        <span class="c1"># iterating over (a,b) where a and b are lists of same size</span>
        <span class="c1"># results in the ith accumulative step in tf.scan receiving</span>
        <span class="c1"># the ith elements of a and b zipped together</span>
        
        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">scan_func</span><span class="p">,</span> <span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">time_delta_grid</span><span class="p">),</span><span class="n">y0</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([[</span><span class="n">y0</span><span class="p">],</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tf_odeint_euler</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    
    <span class="c1"># Convert input to TensorFlow Objects</span>
    
    <span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;y0&#39;</span><span class="p">)</span>
    <span class="n">tf_check_type</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_Tf_Integrator</span><span class="p">()</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">func</span><span class="p">,</span><span class="n">y0</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="running-the-tensorflow-euler-integrator">
<h3>Running the TensorFlow Euler Integrator<a class="headerlink" href="#running-the-tensorflow-euler-integrator" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define a function using Tensorflow math operations. This creates a computational graph.</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="c1"># extracting a single value eg. X[0] returns a single value but</span>
    <span class="c1"># we require a tensor, so we extract a range with one element.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> 
    <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">,</span><span class="n">y</span><span class="o">-</span><span class="n">x</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="n">y0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">epsilon</span><span class="p">)</span>

<span class="c1"># Define the final value (output of scan) that we wish to compute as a variable</span>

<span class="n">state</span> <span class="o">=</span> <span class="n">tf_odeint_euler</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">y0</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>

<span class="c1"># Start a TF session and evaluate state</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[::</span><span class="mi">5</span><span class="p">],</span><span class="n">state</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">0</span><span class="p">,::</span><span class="mi">5</span><span class="p">],</span><span class="s2">&quot;.&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Eulers Solution for x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[::</span><span class="mi">5</span><span class="p">],</span><span class="n">state</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">1</span><span class="p">,::</span><span class="mi">5</span><span class="p">],</span><span class="s2">&quot;.&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Eulers Solution for y&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Day 2_10_0.png" src="../../_images/Day 2_10_0.png" />
</div>
</div>
</div>
<div class="section" id="rk4-integration-function-in-tensorflow">
<h3>RK4 Integration Function in TensorFlow<a class="headerlink" href="#rk4-integration-function-in-tensorflow" title="Permalink to this headline">¶</a></h3>
<p>Now, we implement the RK4 integrator in TensorFlow. Note that here we replace the single step iterator used for the Euler’s with a four step RK4 iterator. In addition, to make the code more modular, we define a function _step_func() that is called by scan_func and calculates the next step of the RK4 integrator. The rest of the program remains the same as the Euler’s method implemented above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tf_check_type</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y0</span><span class="p">):</span> <span class="c1"># Ensure Input is Correct</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">y0</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span> <span class="ow">and</span> <span class="n">t</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Error in Datatype&#39;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">_Tf_Integrator</span><span class="p">():</span>
    
    <span class="k">def</span> <span class="nf">integrate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span> 
        <span class="n">time_delta_grid</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">t</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="k">def</span> <span class="nf">scan_func</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t_dt</span><span class="p">):</span> 
            <span class="n">t</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="n">t_dt</span>
            <span class="n">dy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_step_func</span><span class="p">(</span><span class="n">func</span><span class="p">,</span><span class="n">t</span><span class="p">,</span><span class="n">dt</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="c1"># Make code more modular.</span>
            <span class="k">return</span> <span class="n">y</span> <span class="o">+</span> <span class="n">dy</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">scan_func</span><span class="p">,</span> <span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">time_delta_grid</span><span class="p">),</span><span class="n">y0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([[</span><span class="n">y0</span><span class="p">],</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_step_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">k1</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">half_step</span> <span class="o">=</span> <span class="n">t</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="n">dt_cast</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># Failsafe</span>

        <span class="n">k2</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">dt_cast</span> <span class="o">*</span> <span class="n">k1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">half_step</span><span class="p">)</span>
        <span class="n">k3</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">dt_cast</span> <span class="o">*</span> <span class="n">k2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">half_step</span><span class="p">)</span>
        <span class="n">k4</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">dt_cast</span> <span class="o">*</span> <span class="n">k3</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="n">dt</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">([</span><span class="n">k1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">k2</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">k3</span><span class="p">,</span> <span class="n">k4</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">dt_cast</span> <span class="o">/</span> <span class="mi">6</span><span class="p">)</span>
    

<span class="k">def</span> <span class="nf">tf_odeint_rk4</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">)</span>
    <span class="n">y0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;y0&#39;</span><span class="p">)</span>
    <span class="n">tf_check_type</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_Tf_Integrator</span><span class="p">()</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">func</span><span class="p">,</span><span class="n">y0</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define a function using Tensorflow math operations. This creates a computational graph.</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="c1"># extracting a single value eg. X[0] returns a single value but</span>
    <span class="c1"># we require a tensor, so we extract a range with one element.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> 
    <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">,</span><span class="n">y</span><span class="o">-</span><span class="n">x</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="n">y0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">epsilon</span><span class="p">)</span>

<span class="c1"># Define the final value (output of scan) that we wish to compute as a variable</span>

<span class="n">state</span> <span class="o">=</span> <span class="n">tf_odeint_rk4</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">y0</span><span class="p">,</span><span class="n">t</span><span class="p">)</span>

<span class="c1"># Start a TF session and evaluate state</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[::</span><span class="mi">5</span><span class="p">],</span><span class="n">state</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">0</span><span class="p">,::</span><span class="mi">5</span><span class="p">],</span><span class="s2">&quot;.&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;RK4 Solution for x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[::</span><span class="mi">5</span><span class="p">],</span><span class="n">state</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">1</span><span class="p">,::</span><span class="mi">5</span><span class="p">],</span><span class="s2">&quot;.&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;RK4 Solution for y&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Day 2_13_0.png" src="../../_images/Day 2_13_0.png" />
</div>
</div>
<p><strong>Exercise</strong> Simulate the non-linear Lorentz Attractor using Euler Method and RK4 on TensorFlow which is given by the equations:</p>
<div class="math notranslate nohighlight">
\[\frac{dx}{dt}=\sigma(y-x)\]</div>
<div class="math notranslate nohighlight">
\[\frac{dy}{dt}=x(\rho-z)-y\]</div>
<div class="math notranslate nohighlight">
\[\frac{dz}{dt}=xy-\beta z\]</div>
<p>Use the values <span class="math notranslate nohighlight">\(\sigma =10\)</span>, <span class="math notranslate nohighlight">\(\beta =\frac{8}{3}\)</span>, <span class="math notranslate nohighlight">\(\rho =28\)</span>. You can try simulating this system at two nearby starting conditions and comment on the difference.</p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/lorenz.svg"><img alt="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/lorenz.svg" src="https://raw.githubusercontent.com/neurorishika/PSST/master/Tutorial/Day%202%20Let%20the%20Tensors%20Flow/lorenz.svg" width="400" /></a>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Tutorial\Day 2 Let the Tensors Flow"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="../Day%201%20Of%20Numerical%20Integration%20and%20Python/Day%201.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Day 1: Of Numerical Integration and Python</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="../Day%203%20Cells%20in%20Silicon/Day%203.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Day 3: Cells in Silicon</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Rishika Mohanta and Collins Assisi<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>